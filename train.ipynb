{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a392d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e0fefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"final_data\"   # folder containing train.npz/val.npz/test.npz\n",
    "MODEL_TYPE = \"tcn\"        # \"lstm\" or \"tcn\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4074ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPZSequenceDataset(Dataset):\n",
    "    def __init__(self, npz_path):\n",
    "        d = np.load(npz_path, allow_pickle=True)\n",
    "        self.X = d[\"X\"].astype(np.float32)  # (N,T,F)\n",
    "        self.y = d[\"y\"].astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx]), torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d58d1",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54347648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden=128, num_layers=2, num_classes=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden * 2),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden * 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,T,F)\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]              # (B, 2*hidden)\n",
    "        return self.head(last)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dbbd7a",
   "metadata": {},
   "source": [
    "# TCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d38fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, dilation=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        pad = (k - 1) * dilation // 2\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size=k, dilation=dilation, padding=pad),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(out_ch, out_ch, kernel_size=k, dilation=dilation, padding=pad),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.down = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x):  # x: (B,C,T)\n",
    "        return self.net(x) + self.down(x)\n",
    "\n",
    "class TCNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, channels=(128,128,128), num_classes=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_ch = input_dim\n",
    "        dilation = 1\n",
    "        for ch in channels:\n",
    "            layers.append(TCNBlock(in_ch, ch, k=3, dilation=dilation, dropout=dropout))\n",
    "            in_ch = ch\n",
    "            dilation *= 2\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),   # (B,C,1)\n",
    "            nn.Flatten(),              # (B,C)\n",
    "            nn.LayerNorm(in_ch),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_ch, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,T,F)\n",
    "        x = x.transpose(1, 2)          # (B,F,T)\n",
    "        x = self.tcn(x)                # (B,C,T)\n",
    "        return self.head(x)            # (B,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcf9c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, y):\n",
    "    return (logits.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844dbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, weights, loader, optim=None):\n",
    "    train = optim is not None\n",
    "    model.train(train)\n",
    "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "\n",
    "    ce = nn.CrossEntropyLoss(weight=weights)\n",
    "    \n",
    "    for X, y in loader:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(X)\n",
    "        loss = ce(logits, y)\n",
    "\n",
    "        if train:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optim.step()\n",
    "\n",
    "        bs = X.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc  += accuracy(logits, y) * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / n, total_acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06071e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 0.0382 acc 0.9846 | val loss 1.1726 acc 0.8660\n",
      "Epoch 02 | train loss 0.0003 acc 1.0000 | val loss 1.2620 acc 0.8660\n",
      "Epoch 03 | train loss 0.0002 acc 1.0000 | val loss 1.3293 acc 0.8660\n",
      "Epoch 04 | train loss 0.0001 acc 1.0000 | val loss 1.3806 acc 0.8660\n",
      "Epoch 05 | train loss 0.0001 acc 1.0000 | val loss 1.4277 acc 0.8660\n",
      "Epoch 06 | train loss 0.0001 acc 1.0000 | val loss 1.4708 acc 0.8660\n",
      "Epoch 07 | train loss 0.0001 acc 1.0000 | val loss 1.5061 acc 0.8660\n",
      "Epoch 08 | train loss 0.0000 acc 1.0000 | val loss 1.5386 acc 0.8660\n",
      "Epoch 09 | train loss 0.0000 acc 1.0000 | val loss 1.5673 acc 0.8660\n",
      "Epoch 10 | train loss 0.0000 acc 1.0000 | val loss 1.5953 acc 0.8660\n",
      "Epoch 11 | train loss 0.0000 acc 1.0000 | val loss 1.6212 acc 0.8660\n",
      "Epoch 12 | train loss 0.0000 acc 1.0000 | val loss 1.6453 acc 0.8660\n",
      "Epoch 13 | train loss 0.0000 acc 1.0000 | val loss 1.6651 acc 0.8660\n",
      "Epoch 14 | train loss 0.0000 acc 1.0000 | val loss 1.6848 acc 0.8660\n",
      "Epoch 15 | train loss 0.0000 acc 1.0000 | val loss 1.7056 acc 0.8660\n",
      "Epoch 16 | train loss 0.0000 acc 1.0000 | val loss 1.7274 acc 0.8660\n",
      "Epoch 17 | train loss 0.0000 acc 1.0000 | val loss 1.7418 acc 0.8660\n",
      "Epoch 18 | train loss 0.0000 acc 1.0000 | val loss 1.7587 acc 0.8660\n",
      "Epoch 19 | train loss 0.0000 acc 1.0000 | val loss 1.7789 acc 0.8660\n",
      "Epoch 20 | train loss 0.0000 acc 1.0000 | val loss 1.7883 acc 0.8660\n",
      "Best val acc: 0.8660 | test acc: 0.7104\n",
      "Saved TorchScript model: action_model_jit.pt\n"
     ]
    }
   ],
   "source": [
    "def main(MODEL_TYPE:str):\n",
    "    # load label mapping just for info\n",
    "    with open(f\"{DATA_DIR}/labels.json\", \"r\") as f:\n",
    "        label2id = json.load(f)\n",
    "    num_classes = len(label2id)\n",
    "\n",
    "    train_ds = NPZSequenceDataset(f\"{DATA_DIR}/train.npz\")\n",
    "    val_ds   = NPZSequenceDataset(f\"{DATA_DIR}/val.npz\")\n",
    "    test_ds  = NPZSequenceDataset(f\"{DATA_DIR}/test.npz\")\n",
    "\n",
    "\n",
    "    y_tr = train_ds.y  # numpy array\n",
    "    counts = np.bincount(y_tr)\n",
    "    weights = counts.sum() / (len(counts) * counts)\n",
    "\n",
    "    weights = torch.tensor(weights, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    input_dim = train_ds.X.shape[-1]\n",
    "\n",
    "    if MODEL_TYPE == \"lstm\":\n",
    "        model = LSTMClassifier(input_dim=input_dim, num_classes=num_classes).to(DEVICE)\n",
    "    else:\n",
    "        model = TCNClassifier(input_dim=input_dim, num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "    best_val = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr_loss, tr_acc = run_epoch(model, weights, train_loader, optim)\n",
    "        va_loss, va_acc = run_epoch(model, val_loader, optim=None)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
    "\n",
    "        if va_acc > best_val:\n",
    "            best_val = va_acc\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "    # load best and evaluate on test\n",
    "    model.load_state_dict(best_state)\n",
    "    te_loss, te_acc = run_epoch(model, test_loader, optim=None)\n",
    "    print(f\"Best val acc: {best_val:.4f} | test acc: {te_acc:.4f}\")\n",
    "\n",
    "    # Export to TorchScript for your YOLO pipeline\n",
    "    model.eval()\n",
    "    example = torch.randn(1, 30, input_dim).to(DEVICE)\n",
    "    scripted = torch.jit.trace(model, example)\n",
    "    scripted.save(\"action_model_jit.pt\")\n",
    "    print(\"Saved TorchScript model: action_model_jit.pt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(MODEL_TYPE=\"tcn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16e7caa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true : ['PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps']\n",
      "pred : ['PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps', 'PullUps']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch, json\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "m = torch.jit.load(\"action_model_jit.pt\").to(device).eval()\n",
    "\n",
    "label2id = json.load(open(\"final_data/labels.json\"))\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "d = np.load(\"final_data/test.npz\", allow_pickle=True)\n",
    "X = torch.from_numpy(d[\"X\"][:64]).to(device)   # (64,30,85)\n",
    "y = d[\"y\"][:64]\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = m(X).argmax(1).cpu().numpy()\n",
    "\n",
    "print(\"true :\", [id2label[i] for i in y[:10]])\n",
    "print(\"pred :\", [id2label[i] for i in p[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d403bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [1647  563   71]\n",
      "Class weights: [ 0.46164744  1.35050326 10.70892019]\n"
     ]
    }
   ],
   "source": [
    "train_ds = NPZSequenceDataset(f\"final_data/train.npz\")\n",
    "\n",
    "y_tr = train_ds.y  # numpy array\n",
    "\n",
    "counts = np.bincount(y_tr)\n",
    "print(\"Class counts:\", counts)\n",
    "\n",
    "weights = counts.sum() / (len(counts) * counts)\n",
    "print(\"Class weights:\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45434957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity-det (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
